# GridFS Complete Documentation

## Table of Contents
1. [What is GridFS?](#what-is-gridfs)
2. [Why Use GridFS?](#why-use-gridfs)
3. [How GridFS Works Internally](#how-gridfs-works-internally)
4. [Implementation Architecture](#implementation-architecture)
5. [Code Walkthrough](#code-walkthrough)
6. [MongoDB Collections Structure](#mongodb-collections-structure)
7. [Upload Process Flow](#upload-process-flow)
8. [Retrieval Process Flow](#retrieval-process-flow)
9. [API Endpoints Explained](#api-endpoints-explained)
10. [Frontend Integration](#frontend-integration)

---

## What is GridFS?

**GridFS** is a specification for storing and retrieving files that exceed the BSON-document size limit of **16 MB** in MongoDB.

### Key Concepts:
- **Not a file system**: It's a specification for storing large files in MongoDB
- **Chunking**: Files are divided into smaller pieces (chunks) of 255 KB each
- **Two Collections**: Uses `files` and `chunks` collections
- **Streaming**: Supports efficient streaming of file data

### When to Use GridFS:
âœ… Files larger than 16 MB  
âœ… Need to access portions of files without loading entire file  
âœ… Want to keep files and metadata together in MongoDB  
âœ… Need to replicate files across MongoDB replica sets  

### When NOT to Use GridFS:
âŒ Small files (< 16 MB) - use regular BSON documents  
âŒ Need filesystem-level atomic updates  
âŒ Primary use case is serving static files (use CDN instead)  

---

## Why Use GridFS?

### Problem Without GridFS:
```javascript
// âŒ This won't work for files > 16 MB
db.photos.insert({
  name: "large_photo.jpg",
  data: <binary data>  // Error if > 16 MB!
});
```

### Solution With GridFS:
```javascript
// âœ… GridFS automatically handles large files
const uploadStream = bucket.openUploadStream("large_photo.jpg");
uploadStream.end(fileBuffer);  // Works for any size!
```

### Benefits:
1. **No Size Limit**: Store files of any size
2. **Efficient Streaming**: Read/write without loading entire file into memory
3. **Automatic Chunking**: GridFS handles splitting and reassembly
4. **Metadata Storage**: Store custom metadata with each file
5. **Range Queries**: Retrieve specific byte ranges
6. **Replication**: Files replicate with your MongoDB replica set

---

## How GridFS Works Internally

### The Chunking Mechanism

When you upload a 1 MB file to GridFS:

```
Original File (1 MB)
â”‚
â”œâ”€ Chunk 0 (255 KB) â”€â”€â”€â”€â”€â”
â”œâ”€ Chunk 1 (255 KB) â”€â”€â”€â”€â”€â”¤
â”œâ”€ Chunk 2 (255 KB) â”€â”€â”€â”€â”€â”œâ”€> Stored in uploads.chunks
â””â”€ Chunk 3 (235 KB) â”€â”€â”€â”€â”€â”˜

Metadata â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Stored in uploads.files
```

### Two Collections Created:

#### 1. `uploads.files` (Metadata Collection)
Stores file metadata:
```javascript
{
  _id: ObjectId("..."),
  length: 1048576,              // File size in bytes
  chunkSize: 261120,            // Size of each chunk (255 KB)
  uploadDate: ISODate("..."),
  filename: "photo.jpg",
  contentType: "image/jpeg",
  metadata: {}                  // Custom metadata
}
```

#### 2. `uploads.chunks` (Data Collection)
Stores the actual file data in chunks:
```javascript
{
  _id: ObjectId("..."),
  files_id: ObjectId("..."),    // References uploads.files._id
  n: 0,                         // Chunk number (0-indexed)
  data: BinData(0, "...")       // Actual binary data (max 255 KB)
}
{
  _id: ObjectId("..."),
  files_id: ObjectId("..."),
  n: 1,                         // Second chunk
  data: BinData(0, "...")
}
// ... more chunks
```

### Why 255 KB Chunks?
- **BSON Limit**: Documents can be up to 16 MB
- **Efficiency**: 255 KB is optimal for network transfer and memory usage
- **Indexing**: Smaller chunks = better index performance

---

## Implementation Architecture

### Technology Stack

**Backend:**
```
Express.js â”€â”€> Handles HTTP requests
    â”‚
    â”œâ”€> Multer â”€â”€> Receives file uploads (memory storage)
    â”‚
    â”œâ”€> Mongoose â”€â”€> MongoDB connection
    â”‚
    â””â”€> GridFSBucket â”€â”€> Handles file chunking & storage
```

**Frontend:**
```
React â”€â”€> User Interface
    â”‚
    â”œâ”€> Axios â”€â”€> HTTP client for API calls
    â”‚
    â””â”€> FormData â”€â”€> Sends files to backend
```

**Database:**
```
MongoDB Atlas (Cloud)
    â”‚
    â””â”€> gridfs-demo database
        â”œâ”€> uploads.files (metadata)
        â””â”€> uploads.chunks (file data)
```

### Why This Approach?

**Original Attempt (Failed):**
```javascript
// âŒ multer-gridfs-storage has compatibility issues
const storage = new GridFsStorage({
  url: mongoURI,
  file: (req, file) => ({ filename: file.originalname })
});
```

**Current Solution (Working):**
```javascript
// âœ… Manual implementation with memoryStorage
const storage = multer.memoryStorage();  // Buffer in memory
const upload = multer({ storage });

// Then manually write to GridFS
const uploadStream = gridfsBucket.openUploadStream(filename);
uploadStream.end(req.file.buffer);
```

---

## Code Walkthrough

### Backend Setup ([server/index.js](file:///Users/roshanrejik/Desktop/Interview/server/index.js))

#### 1. Initialize MongoDB Connection
```javascript
const mongoose = require('mongoose');
const mongoURI = process.env.MONGODB_URI;

// Create a separate connection for GridFS
const conn = mongoose.createConnection(mongoURI, {
  useNewUrlParser: true,
  useUnifiedTopology: true,
});
```

**Why separate connection?**
- GridFS needs access to the raw MongoDB database object
- Allows us to use `GridFSBucket` directly

#### 2. Initialize GridFS Bucket
```javascript
let gridfsBucket;

conn.once('open', () => {
  // Create GridFS bucket with custom bucket name
  gridfsBucket = new mongoose.mongo.GridFSBucket(conn.db, {
    bucketName: 'uploads'  // Creates uploads.files & uploads.chunks
  });
  
  console.log('GridFS initialized');
});
```

**What happens here:**
- `GridFSBucket` is a native MongoDB driver class
- `bucketName: 'uploads'` creates two collections:
  - `uploads.files`
  - `uploads.chunks`
- Default bucket name would be `fs.files` and `fs.chunks`

#### 3. Configure Multer
```javascript
// Use memory storage (file stored in RAM temporarily)
const storage = multer.memoryStorage();
const upload = multer({ storage });
```

**Why memoryStorage?**
- File is stored in `req.file.buffer` (Buffer object)
- We can then write this buffer to GridFS
- Alternative would be disk storage, but that's slower

#### 4. Upload Endpoint
```javascript
app.post('/upload', upload.single('file'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No file uploaded' });
    }

    // Create unique filename with timestamp
    const filename = `${Date.now()}-${req.file.originalname}`;
    
    // Create upload stream to GridFS
    const uploadStream = gridfsBucket.openUploadStream(filename, {
      contentType: req.file.mimetype
    });

    // Write file buffer to GridFS (this triggers chunking)
    uploadStream.end(req.file.buffer);

    // Listen for completion
    uploadStream.on('finish', () => {
      res.json({
        success: true,
        file: {
          filename: filename,
          id: uploadStream.id,
          contentType: req.file.mimetype,
          size: req.file.size
        }
      });
    });

    // Handle errors
    uploadStream.on('error', (error) => {
      res.status(500).json({ error: error.message });
    });
  } catch (err) {
    return res.status(500).json({ error: err.message });
  }
});
```

**Step-by-step breakdown:**

1. **Multer receives file**: `upload.single('file')` middleware
   - File is in `req.file.buffer` (binary data)
   - Metadata in `req.file.originalname`, `req.file.mimetype`, etc.

2. **Create upload stream**: `gridfsBucket.openUploadStream(filename, options)`
   - Returns a writable stream
   - GridFS will handle chunking automatically

3. **Write buffer**: `uploadStream.end(req.file.buffer)`
   - Sends entire file buffer to the stream
   - GridFS splits it into 255 KB chunks
   - Each chunk is saved to `uploads.chunks`
   - Metadata is saved to `uploads.files`

4. **Event listeners**:
   - `finish`: Triggered when upload completes successfully
   - `error`: Triggered if something goes wrong

#### 5. List Files Endpoint
```javascript
app.get('/files', async (req, res) => {
  try {
    // Find all files in the bucket
    const files = await gridfsBucket.find().toArray();

    if (!files || files.length === 0) {
      return res.status(404).json({ error: 'No files found' });
    }

    return res.json(files);
  } catch (err) {
    return res.status(500).json({ error: err.message });
  }
});
```

**What `gridfsBucket.find()` returns:**
```javascript
[
  {
    _id: ObjectId("..."),
    length: 524288,
    chunkSize: 261120,
    uploadDate: ISODate("2026-01-20T12:00:00Z"),
    filename: "1768910560899-test_image.gif",
    contentType: "image/gif"
  },
  // ... more files
]
```

#### 6. Stream Image Endpoint
```javascript
app.get('/image/:filename', async (req, res) => {
  try {
    // Find file by filename
    const files = await gridfsBucket.find({ 
      filename: req.params.filename 
    }).toArray();

    if (!files || files.length === 0) {
      return res.status(404).json({ error: 'File not found' });
    }

    const file = files[0];

    // Check if it's an image
    if (file.contentType === 'image/jpeg' || 
        file.contentType === 'image/png' || 
        file.contentType === 'image/jpg') {
      
      // Create download stream
      const readStream = gridfsBucket.openDownloadStreamByName(
        req.params.filename
      );
      
      // Pipe directly to response
      readStream.pipe(res);
    } else {
      res.status(404).json({ error: 'Not an image' });
    }
  } catch (err) {
    return res.status(500).json({ error: err.message });
  }
});
```

**How streaming works:**

1. **Find file**: Query `uploads.files` for metadata
2. **Create read stream**: `openDownloadStreamByName(filename)`
   - GridFS finds all chunks for this file
   - Creates a readable stream
3. **Pipe to response**: `readStream.pipe(res)`
   - Chunks are read sequentially
   - Reassembled automatically
   - Sent directly to HTTP response
   - **No need to load entire file into memory!**

---

## MongoDB Collections Structure

### View in MongoDB Compass or Shell

```bash
# Connect to MongoDB
mongo "mongodb+srv://roshan:password@cluster0.wrzaoj3.mongodb.net/gridfs-demo"

# View files collection
db.uploads.files.find().pretty()

# View chunks collection
db.uploads.chunks.find().pretty()
```

### Example Data

#### uploads.files
```javascript
{
  "_id": ObjectId("679e1a2b3c4d5e6f7a8b9c0d"),
  "length": 1048576,                    // 1 MB file
  "chunkSize": 261120,                  // 255 KB chunks
  "uploadDate": ISODate("2026-01-20T12:00:00.000Z"),
  "filename": "1768910560899-photo.jpg",
  "contentType": "image/jpeg"
}
```

#### uploads.chunks
```javascript
// Chunk 0
{
  "_id": ObjectId("679e1a2b3c4d5e6f7a8b9c0e"),
  "files_id": ObjectId("679e1a2b3c4d5e6f7a8b9c0d"),  // Links to file
  "n": 0,                                // First chunk
  "data": BinData(0, "/9j/4AAQSkZJRg...")  // 255 KB of data
}

// Chunk 1
{
  "_id": ObjectId("679e1a2b3c4d5e6f7a8b9c0f"),
  "files_id": ObjectId("679e1a2b3c4d5e6f7a8b9c0d"),
  "n": 1,                                // Second chunk
  "data": BinData(0, "AQEBAQEBAQEBAQ...")  // 255 KB of data
}

// Chunk 2
{
  "_id": ObjectId("679e1a2b3c4d5e6f7a8b9c10"),
  "files_id": ObjectId("679e1a2b3c4d5e6f7a8b9c0d"),
  "n": 2,                                // Third chunk
  "data": BinData(0, "ZGF0YWRhdGFkYX...")  // 255 KB of data
}

// Chunk 3 (last chunk, smaller)
{
  "_id": ObjectId("679e1a2b3c4d5e6f7a8b9c11"),
  "files_id": ObjectId("679e1a2b3c4d5e6f7a8b9c0d"),
  "n": 3,                                // Fourth chunk
  "data": BinData(0, "bGFzdCBjaHVuaw...")  // 238 KB of data
}
```

**Total chunks for 1 MB file:**
- Chunk 0: 255 KB
- Chunk 1: 255 KB
- Chunk 2: 255 KB
- Chunk 3: 238 KB (remaining)
- **Total: 4 chunks = 1,003 KB â‰ˆ 1 MB**

---

## Upload Process Flow

### Complete Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚
â”‚  (Frontend) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. User selects file
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FormData Created   â”‚
â”‚  file: <File>       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 2. POST /upload
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Express Server    â”‚
â”‚   Multer Middleware â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 3. File buffered in memory
       â”‚    req.file.buffer = <Buffer>
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Upload Handler     â”‚
â”‚  Creates filename   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 4. gridfsBucket.openUploadStream()
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GridFS Bucket      â”‚
â”‚  Creates stream     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 5. uploadStream.end(buffer)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GridFS Chunking Engine         â”‚
â”‚  - Splits buffer into 255KB     â”‚
â”‚  - Creates chunk documents      â”‚
â”‚  - Saves to uploads.chunks      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 6. All chunks saved
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Metadata Saved                 â”‚
â”‚  - Creates file document        â”‚
â”‚  - Saves to uploads.files       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 7. 'finish' event fired
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Response Sent      â”‚
â”‚  { success: true }  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 8. JSON response
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚
â”‚ Shows successâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detailed Steps

**Step 1: User Selects File**
```javascript
// Frontend - User clicks file input
<input type="file" onChange={handleFileChange} />

// File object created
File {
  name: "photo.jpg",
  size: 1048576,
  type: "image/jpeg",
  lastModified: 1768910560899
}
```

**Step 2: Frontend Sends File**
```javascript
const formData = new FormData();
formData.append('file', file);

axios.post('http://localhost:5001/upload', formData, {
  headers: { 'Content-Type': 'multipart/form-data' }
});
```

**Step 3: Multer Processes Upload**
```javascript
// Multer middleware intercepts request
upload.single('file')

// File is buffered in memory
req.file = {
  fieldname: 'file',
  originalname: 'photo.jpg',
  encoding: '7bit',
  mimetype: 'image/jpeg',
  buffer: <Buffer ff d8 ff e0 00 10 ...>,  // Actual file data
  size: 1048576
}
```

**Step 4: Create Upload Stream**
```javascript
const uploadStream = gridfsBucket.openUploadStream(filename, {
  contentType: req.file.mimetype
});

// uploadStream is a WritableStream
// GridFS is ready to receive data
```

**Step 5: Write Buffer to Stream**
```javascript
uploadStream.end(req.file.buffer);

// GridFS receives the buffer
// Internally splits into chunks:
// - Chunk 0: buffer.slice(0, 261120)
// - Chunk 1: buffer.slice(261120, 522240)
// - Chunk 2: buffer.slice(522240, 783360)
// - Chunk 3: buffer.slice(783360, 1048576)
```

**Step 6: GridFS Saves Chunks**
```javascript
// For each chunk, GridFS inserts:
db.uploads.chunks.insertOne({
  files_id: ObjectId("..."),
  n: 0,  // chunk number
  data: BinData(0, <chunk data>)
});
```

**Step 7: GridFS Saves Metadata**
```javascript
db.uploads.files.insertOne({
  _id: ObjectId("..."),
  length: 1048576,
  chunkSize: 261120,
  uploadDate: new Date(),
  filename: "1768910560899-photo.jpg",
  contentType: "image/jpeg"
});
```

**Step 8: Success Response**
```javascript
uploadStream.on('finish', () => {
  res.json({
    success: true,
    file: {
      filename: "1768910560899-photo.jpg",
      id: uploadStream.id,
      contentType: "image/jpeg",
      size: 1048576
    }
  });
});
```

---

## Retrieval Process Flow

### Complete Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚
â”‚  Requests   â”‚
â”‚  /image/    â”‚
â”‚  photo.jpg  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. GET /image/photo.jpg
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Express Server     â”‚
â”‚  Route Handler      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 2. Query uploads.files
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MongoDB Query                  â”‚
â”‚  db.uploads.files.find({        â”‚
â”‚    filename: "photo.jpg"        â”‚
â”‚  })                             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 3. File metadata found
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Create Read Stream â”‚
â”‚  openDownloadStream â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 4. Stream created
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GridFS Reads Chunks            â”‚
â”‚  - Queries uploads.chunks       â”‚
â”‚  - Ordered by 'n' field         â”‚
â”‚  - Reads sequentially           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 5. Chunks reassembled
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pipe to Response   â”‚
â”‚  readStream.pipe()  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 6. Binary data streamed
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚
â”‚ Displays    â”‚
â”‚ Image       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detailed Steps

**Step 1: Browser Requests Image**
```javascript
// Frontend
<img src="http://localhost:5001/image/1768910560899-photo.jpg" />
```

**Step 2: Find File Metadata**
```javascript
const files = await gridfsBucket.find({ 
  filename: req.params.filename 
}).toArray();

// Returns:
[{
  _id: ObjectId("..."),
  length: 1048576,
  chunkSize: 261120,
  uploadDate: ISODate("..."),
  filename: "1768910560899-photo.jpg",
  contentType: "image/jpeg"
}]
```

**Step 3: Create Download Stream**
```javascript
const readStream = gridfsBucket.openDownloadStreamByName(
  req.params.filename
);

// GridFS internally:
// 1. Finds all chunks with matching files_id
// 2. Sorts by 'n' field (chunk number)
// 3. Creates readable stream
```

**Step 4: GridFS Reads Chunks**
```javascript
// GridFS queries:
db.uploads.chunks.find({ 
  files_id: ObjectId("...") 
}).sort({ n: 1 })

// Returns chunks in order:
// Chunk 0, Chunk 1, Chunk 2, Chunk 3
```

**Step 5: Stream to Response**
```javascript
readStream.pipe(res);

// Chunks are read one by one:
// - Read Chunk 0 â†’ send to response
// - Read Chunk 1 â†’ send to response
// - Read Chunk 2 â†’ send to response
// - Read Chunk 3 â†’ send to response
// - Close stream
```

**Step 6: Browser Receives Data**
```
HTTP Response:
Content-Type: image/jpeg
Content-Length: 1048576

<binary image data>
```

---

## API Endpoints Explained

### 1. POST /upload
**Purpose**: Upload a file to GridFS

**Request:**
```http
POST /upload HTTP/1.1
Content-Type: multipart/form-data

------WebKitFormBoundary
Content-Disposition: form-data; name="file"; filename="photo.jpg"
Content-Type: image/jpeg

<binary data>
------WebKitFormBoundary--
```

**Response:**
```json
{
  "success": true,
  "file": {
    "filename": "1768910560899-photo.jpg",
    "id": "679e1a2b3c4d5e6f7a8b9c0d",
    "contentType": "image/jpeg",
    "size": 1048576
  }
}
```

### 2. GET /files
**Purpose**: List all uploaded files

**Request:**
```http
GET /files HTTP/1.1
```

**Response:**
```json
[
  {
    "_id": "679e1a2b3c4d5e6f7a8b9c0d",
    "length": 1048576,
    "chunkSize": 261120,
    "uploadDate": "2026-01-20T12:00:00.000Z",
    "filename": "1768910560899-photo.jpg",
    "contentType": "image/jpeg"
  },
  {
    "_id": "679e1a2b3c4d5e6f7a8b9c0e",
    "length": 524288,
    "chunkSize": 261120,
    "uploadDate": "2026-01-20T12:05:00.000Z",
    "filename": "1768910620000-image.png",
    "contentType": "image/png"
  }
]
```

### 3. GET /image/:filename
**Purpose**: Stream an image file

**Request:**
```http
GET /image/1768910560899-photo.jpg HTTP/1.1
```

**Response:**
```http
HTTP/1.1 200 OK
Content-Type: image/jpeg

<binary image data streamed>
```

### 4. DELETE /files/:id
**Purpose**: Delete a file from GridFS

**Request:**
```http
DELETE /files/679e1a2b3c4d5e6f7a8b9c0d HTTP/1.1
```

**Response:**
```json
{
  "success": true,
  "message": "File deleted"
}
```

**What happens:**
- Deletes document from `uploads.files`
- Deletes all associated chunks from `uploads.chunks`

---

## Frontend Integration

### React Component ([client/src/App.js](file:///Users/roshanrejik/Desktop/Interview/client/src/App.js))

#### State Management
```javascript
const [file, setFile] = useState(null);           // Selected file
const [message, setMessage] = useState({});       // Success/error messages
const [files, setFiles] = useState([]);           // List of uploaded files
const [loading, setLoading] = useState(false);    // Loading state
const [uploading, setUploading] = useState(false); // Upload in progress
```

#### File Selection
```javascript
const handleFileChange = (e) => {
  const selectedFile = e.target.files[0];
  
  if (selectedFile) {
    // Validate file type
    if (!selectedFile.type.startsWith('image/')) {
      setMessage({ 
        text: 'Please select an image file', 
        type: 'error' 
      });
      setFile(null);
      return;
    }
    
    setFile(selectedFile);
    setMessage({ text: '', type: '' });
  }
};
```

#### Upload Function
```javascript
const handleUpload = async (e) => {
  e.preventDefault();
  
  if (!file) {
    setMessage({ text: 'Please select a file first', type: 'error' });
    return;
  }

  // Create FormData
  const formData = new FormData();
  formData.append('file', file);

  setUploading(true);
  setMessage({ text: '', type: '' });

  try {
    // Send to backend
    const response = await axios.post(`${API_URL}/upload`, formData, {
      headers: {
        'Content-Type': 'multipart/form-data',
      },
    });

    // Show success message
    setMessage({ 
      text: `File uploaded successfully: ${response.data.file.filename}`, 
      type: 'success' 
    });
    
    setFile(null);
    document.getElementById('file-input').value = '';
    
    // Refresh gallery
    fetchFiles();
  } catch (error) {
    setMessage({ 
      text: `Upload failed: ${error.response?.data?.error || error.message}`, 
      type: 'error' 
    });
  } finally {
    setUploading(false);
  }
};
```

#### Fetch Files
```javascript
const fetchFiles = async () => {
  setLoading(true);
  try {
    const response = await axios.get(`${API_URL}/files`);
    setFiles(response.data);
  } catch (error) {
    if (error.response && error.response.status === 404) {
      setFiles([]);
    } else {
      console.error('Error fetching files:', error);
    }
  } finally {
    setLoading(false);
  }
};

// Fetch on component mount
useEffect(() => {
  fetchFiles();
}, []);
```

#### Display Gallery
```javascript
<div className="gallery">
  {files.map((file) => (
    <div key={file._id} className="gallery-item">
      <img 
        src={`${API_URL}/image/${file.filename}`} 
        alt={file.filename}
      />
      <div className="gallery-item-info">
        <p><strong>Name:</strong> {file.filename}</p>
        <p><strong>Size:</strong> {(file.length / 1024).toFixed(2)} KB</p>
      </div>
    </div>
  ))}
</div>
```

---

## Summary

### Key Takeaways

1. **GridFS = Chunking System**
   - Splits files into 255 KB pieces
   - Stores in two collections: `files` and `chunks`

2. **Upload Process**
   - Multer buffers file in memory
   - GridFSBucket streams buffer to MongoDB
   - Automatic chunking happens behind the scenes

3. **Retrieval Process**
   - GridFS finds all chunks
   - Reassembles them in order
   - Streams directly to HTTP response

4. **No Size Limits**
   - Can store files of any size
   - Memory efficient (streaming)
   - Works with MongoDB Atlas cloud

5. **Production Ready**
   - Error handling included
   - Works with cloud MongoDB
   - Scalable architecture

### File Locations
- **Backend**: `/Users/roshanrejik/Desktop/Interview/server/`
- **Frontend**: `/Users/roshanrejik/Desktop/Interview/client/`
- **Database**: MongoDB Atlas cloud

### Running the Application
```bash
# Terminal 1: Start backend
cd server
npm start

# Terminal 2: Start frontend
cd client
npm start

# Open browser
http://localhost:3000
```

Your GridFS implementation is complete and production-ready! ğŸš€
